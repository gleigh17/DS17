{"paragraphs":[{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala","tableHide":false},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485720828855_994552545","id":"20170129-151348_9751986","dateCreated":"2017-01-29T15:13:48-0500","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3306","text":"// Imports\r\nimport org.apache.spark.sql.functions._\r\nimport org.joda.time.format.DateTimeFormat\r\n\r\n// Load data - adjust the path to the location of your data\r\nval inputPath =  \"c:/USERS/gleigh/downloads/pollutionData204273.csv/*\"\r\nval airTraffic = sqlContext.read\r\n        .format(\"com.databricks.spark.csv\")\r\n        .option(\"header\", \"true\") // Use first line of all files as header\r\n        .option(\"delimiter\", \",\")\r\n        .option(\"inferSchema\", \"true\") {"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.streaming._\n\nimport org.apache.spark.streaming.twitter._\n\nimport org.apache.spark.storage.StorageLevel\n\nimport scala.io.Source\n\nimport scala.collection.mutable.HashMap\n\nimport java.io.File\n\nimport org.apache.log4j.Logger\n\nimport org.apache.log4j.Level\n\nimport sys.process.stringSeqToProcess\n"},"focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485479461831_-1612731633","id":"20170126-201101_1689717641","dateCreated":"2017-01-26T20:11:01-0500","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2339","dateUpdated":"2017-01-26T20:11:42-0500","dateFinished":"2017-01-26T20:11:45-0500","dateStarted":"2017-01-26T20:11:42-0500","result":// Automatically infer data types\r\n        .load(inputPath)\r\n\r\n\r\n// Register as Spark SQL Table\r\nfeaturedTraffic.registerTempTable(\"pollution\")\r\n// sqlContext.cacheTable(\"pollution\")","dateUpdated":"2017-01-29T15:23:14-0500","errorMessage":""}],"name":"Pollution Measurements","id":"2CAEQSH9V","angularObjects":{"2C7UBU6Q3:shared_process":[],"2C8TVZKPM:shared_process":[],"2C7GT2BBM:shared_process":[],"2CAMJ6W6P:shared_process":[],"2C8VS3XJ9:shared_process":[],"2C9PPF2WM:shared_process":[],"2C7GN6J98:shared_process":[],"2CAH4CPVA:shared_process":[],"2CAK4TASQ:shared_process":[],"2C93ZS8Y9:shared_process":[],"2C7RS9MBF:shared_process":[],"2C6V7TT9D:shared_process":[],"2C8TB7J6J:shared_process":[],"2C734DA4Z:shared_process":[],"2C81TCJW1:shared_process":[],"2C6WN6NEJ:shared_process":[],"2C787RZS8:shared_process":[],"2C9Q4QEKP:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}
{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.streaming._\n\nimport org.apache.spark.streaming.twitter._\n\nimport org.apache.spark.storage.StorageLevel\n\nimport scala.io.Source\n\nimport scala.collection.mutable.HashMap\n\nimport java.io.File\n\nimport org.apache.log4j.Logger\n\nimport org.apache.log4j.Level\n\nimport sys.process.stringSeqToProcess\n"},"focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1485479461831_-1612731633","id":"20170126-201101_1689717641","dateCreated":"2017-01-26T20:11:01-0500","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2339","dateUpdated":"2017-01-26T20:11:42-0500","dateFinished":"2017-01-26T20:11:45-0500","dateStarted":"2017-01-26T20:11:42-0500","result":